{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import f1_score, classification_report, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_selection import f_regression, f_classif, RFE, VarianceThreshold, chi2, SelectKBest, SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and remove unwanted columns\n",
    "data = pd.read_excel('augmented sample.xlsx').drop(['index',\n",
    "                                                    'Formation_energy'],\n",
    "                                                    axis=1)\n",
    "data = data.set_index(['Material Composition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into X and y(Energy Above Hull)\n",
    "X = data.drop(['EnergyAboveHull'], axis=1)\n",
    "y = data['EnergyAboveHull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples 2138 \n",
      "Number of features: 962\n"
     ]
    }
   ],
   "source": [
    "# preview the shape of the dataframe\n",
    "sample_size = X.shape[0]\n",
    "feature_size = X.shape[1]\n",
    "print(\"Number of samples\", sample_size,\n",
    "      \"\\nNumber of features:\", feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test data\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, \n",
    "                                                          test_size=0.2, \n",
    "                                                          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the y\n",
    "y_clf = np.zeros_like(y)\n",
    "y_trainval_clf = np.zeros_like(y_trainval)\n",
    "y_test_clf = np.zeros_like(y_test)\n",
    "\n",
    "# samples with EnergyAboveHull larger than 40 will be marked as unstable\n",
    "# unstable = 0, stable = 1\n",
    "y_clf = [1*(EAH<=40) for EAH in y]\n",
    "y_trainval_clf = [1*(EAH<=40) for EAH in y_trainval]\n",
    "y_test_clf = [1*(EAH<=40) for EAH in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for classification:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples for classification:  1710\n",
      "Number of training labels for classification:  1710\n",
      "Number of test samples for classification:  428\n",
      "Number of test labels for classification:  428\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples for classification: \", \n",
    "      X_trainval.shape[0])\n",
    "print(\"Number of training labels for classification: \", \n",
    "      len(y_trainval_clf))\n",
    "print(\"Number of test samples for classification: \", \n",
    "      X_test.shape[0])\n",
    "print(\"Number of test labels for classification: \", \n",
    "      len(y_test_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for regression:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples for regression:  1710\n",
      "Number of training labels for regression:  1710\n",
      "Number of test samples for regression:  428\n",
      "Number of test labels for regression:  428\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples for regression: \", \n",
    "      X_trainval.shape[0])\n",
    "print(\"Number of training labels for regression: \", \n",
    "      len(y_trainval))\n",
    "print(\"Number of test samples for regression: \", \n",
    "      X_test.shape[0])\n",
    "print(\"Number of test labels for regression: \", \n",
    "      len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **XGB Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**best parameters**\n",
    "\n",
    "{'kbest__k': 250, 'model__colsample_bytree': 0.6, 'model__max_depth': 5, 'model__n_estimators': 150, 'pca__n_components': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model construction\n",
    "model = xgb.XGBRegressor(colsample_bytree=0.6, max_depth=5, n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best pipeline construction\n",
    "pipeline = Pipeline([\n",
    "    ('variance threshold', VarianceThreshold()),\n",
    "    ('kbest', SelectKBest(f_regression, k=250)),\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=25)), \n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 10\n",
    "avg_mae = []\n",
    "avg_rmse = []\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=(1/fold))\n",
    "    pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae 27.484 ± 4.608\n"
     ]
    }
   ],
   "source": [
    "print('average mae', \n",
    "      '{:.3f}'.format(np.mean(avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(avg_mae)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rmse 47.229 ± 27.223\n"
     ]
    }
   ],
   "source": [
    "print('average rmse', \n",
    "      '{:.3f}'.format(np.mean(avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **XGB Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**best parameters**\n",
    "\n",
    "{'kbest__k': 450, 'model__colsample_bytree': 0.6, 'model__max_depth': 5, 'model__n_estimators': 650, 'pca__n_components': 50}\n",
    "\n",
    "{'sampling__k_neighbors': 1, 'sampling__m_neighbors': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model construction\n",
    "model = xgb.XGBClassifier(max_depth=5, \n",
    "                          n_estimators=650, \n",
    "                          colsample_bytree=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best pipeline construction\n",
    "pipeline = Pipeline([\n",
    "    ('sampling', BorderlineSMOTE(k_neighbors=1, \n",
    "                                 m_neighbors=1, \n",
    "                                 sampling_strategy='minority')),\n",
    "    ('variance threshold', VarianceThreshold()),\n",
    "    ('kbest', SelectKBest(f_classif, k=450)),\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=50)), \n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 10\n",
    "weighted_avg_f1 = []\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y_clf, test_size=(1/fold))\n",
    "    pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    weighted_avg_f1.append(report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score 0.919 ± 0.020\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score', \n",
    "      '{:.3f}'.format(np.mean(weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
